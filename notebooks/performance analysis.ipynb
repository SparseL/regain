{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance analysis\n",
    "This notebook is create to compare the performance of different algorithms for graphical inference, namely graphical lasso (GL or GLASSO), latent graph lasso (LVGLASSO), time-varying graphical lasso (TVGL) wuth our method, latent variable time-varying graphical lasso (LVGL).\n",
    "\n",
    "## Before proceeding\n",
    "Other methods are not necessarily implemented in Python. Therefore, this is a list of required steps in order to successfully install the code.\n",
    "\n",
    "### Install instructions for\n",
    "#### 1a. GL (scikit-learn implementation)\n",
    "For this, it is not required to do anything, as `sklearn` should be already installed in your system as it is a dependency of `regain`. Otherwise, install it as first thing with \n",
    "```\n",
    "conda install scikit-learn\n",
    "```\n",
    "or \n",
    "```\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "#### 1b. GLASSO (R implementation)\n",
    "This is the R implementation for graphical lasso, called GLASSO. It is available as an R package, thus requiring R installed in your system. Then, in R console (simply call `R` from a command line):\n",
    "```R\n",
    "install.packages(\"glasso\")\n",
    "```\n",
    "Refer to [GLASSO documentation](https://cran.r-project.org/web/packages/glasso/glasso.pdf) for further information.\n",
    "\n",
    "#### 2. LVGLASSO (Matlab implementation)\n",
    "This requires to have [Matlab installed](https://it.mathworks.com/help/install/ug/install-mathworks-software.html) (version2016b or higher) and [Matlab engine for Python](https://it.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html).\n",
    "Then, [download the code](https://www.math.ucdavis.edu/~sqma/ADMM-LVGLasso) and unpack the folder.\n",
    "Ensure to have a file called `ADMM_B.m`. Save the location of the code, as it will be necessary to call the `ADMM_B.m` script.\n",
    "\n",
    "**NOTE:** There is a so-called [LVGLASSO in the R packages](https://www.rdocumentation.org/packages/lvnet/versions/0.3.2/topics/lvglasso). Note that THIS IS NOT RIGHT, as it is implemented in a different way and it requires to specify a priori the number of latent variables. See the link above for further details.\n",
    "\n",
    "**NOTE 2:** Our `regain` package has a Python wrapper that ease the calling of such Matlab functions. Therefore, conversions of numpy arrays to Matlab matrices are done under the hood from the script `regain/wrappers/lvglasso/LVGLASSO.m`.\n",
    "\n",
    "#### 3. TVGL (Python implementation)\n",
    "Since it is a Python implementation, this does not require additional software (beside having `git` installed). However, there is a little modification in the source code to do in order to obtain additional results, such as the number of iterations and the estimated covariance matrices.\n",
    "\n",
    "1. Clone the repo (https://github.com/davidhallac/TVGL) in a folder, with\n",
    "```bash\n",
    "git clone https://github.com/davidhallac/TVGL.git\n",
    "```\n",
    "Its requirements are [`cvxpy`](http://www.cvxpy.org/en/latest/install/index.html) and [`snap`](https://snap.stanford.edu/snappy/) installed. \n",
    "\n",
    "2. Modify the line 76 of ./TVGL/TVGL.py (ie, `return thetaSet`) with \n",
    "```\n",
    "return thetaSet, empCovSet, gvx.status, gvx\n",
    "```\n",
    "3. Add after the line 454 of ./TVGL/inferGraphL2.py (and other norms if required)\n",
    "```\n",
    "self.n_iter_ = num_iterations\n",
    "```\n",
    "\n",
    "#### 4. REGAIN\n",
    "Of course, first of all you should download and install the `regain` package (our method). If you haven't done it yet, do it now!\n",
    "\n",
    "```\n",
    "conda install -c fdtomasi regain\n",
    "```\n",
    "or\n",
    "```\n",
    "pip install regain\n",
    "```\n",
    "\n",
    "Or, you have the source code, `mv` to the `regain` folder, then\n",
    "```\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "and that's it. Now you are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matlab.engine\n",
    "import matlab\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from scipy.io import loadmat\n",
    "from sklearn.datasets import make_sparse_spd_matrix\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.utils.extmath import squared_norm\n",
    "from sklearn.covariance import GraphLasso, empirical_covariance\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "\n",
    "from regain import datasets; reload(datasets)\n",
    "from regain import prox; reload(prox)\n",
    "from regain.covariance import graph_lasso_; reload(graph_lasso_);\n",
    "from regain.covariance import time_graph_lasso_; reload(time_graph_lasso_);\n",
    "from regain.covariance import latent_graph_lasso_; reload(latent_graph_lasso_);\n",
    "from regain.covariance import latent_time_graph_lasso_; reload(latent_time_graph_lasso_);\n",
    "from regain import utils; reload(utils)\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances of the different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.covariance import log_likelihood\n",
    "def likelihood_score(X, precision_):\n",
    "    # compute empirical covariance of the test set\n",
    "    location_ = X.mean(1).reshape(X.shape[0], 1, X.shape[2])\n",
    "    test_cov = np.array([empirical_covariance(\n",
    "        x, assume_centered=True) for x in X - location_])\n",
    "\n",
    "    res = sum(log_likelihood(S, K) for S, K in zip(\n",
    "        test_cov, precision_))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from rpy2.robjects.packages import importr\n",
    "    glasso = importr('glasso').glasso\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import sys; sys.path.append(\"/home/fede/src/TVGL\")\n",
    "import TVGL\n",
    "\n",
    "\n",
    "def gl_results(data_grid, K, K_obs, ells, **params):\n",
    "    mdl = graph_lasso_.GraphLasso(\n",
    "        assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=500, rho=1. / np.sqrt(data_grid.shape[0]))\n",
    "\n",
    "    tic = time.time()\n",
    "    iters = []\n",
    "    precisions = []\n",
    "    for d in data_grid.transpose(2, 0, 1):\n",
    "        mdl.set_params(**params).fit(d)\n",
    "        iters.append(mdl.n_iter_)\n",
    "        precisions.append(mdl.precision_)\n",
    "    tac = time.time()\n",
    "    iterations = np.max(iters)\n",
    "    precisions = np.array(precisions)\n",
    "\n",
    "    F1score = utils.structure_error(K, precisions)['f1']\n",
    "    MSE_observed = None\n",
    "    MSE_precision = utils.error_norm(K, precisions)\n",
    "    MSE_latent = None\n",
    "    mean_rank_error = None\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac - tic,\n",
    "               iterations=iterations,\n",
    "               F1score=F1score,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               note=None,\n",
    "               estimator=mdl)\n",
    "    return res\n",
    "\n",
    "def lgl_results(data_grid, K, K_obs, ells, **params):\n",
    "    mdl = latent_graph_lasso_.LatentGraphLasso(\n",
    "        assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=500, rho=1./ np.sqrt(data_grid.shape[0]))\n",
    "\n",
    "    tic = time.time()\n",
    "    iters = []\n",
    "    precisions, latents = [], []\n",
    "    for d in data_grid.transpose(2,0,1):\n",
    "        mdl.set_params(**params).fit(d)\n",
    "        iters.append(mdl.n_iter_)\n",
    "        precisions.append(mdl.precision_)\n",
    "        latents.append(mdl.latent_)\n",
    "    tac = time.time()\n",
    "    iterations = np.max(iters)\n",
    "    precisions = np.array(precisions)\n",
    "    latents = np.array(latents)\n",
    "\n",
    "    F1score = utils.structure_error(K, precisions)['f1']\n",
    "    MSE_observed = utils.error_norm(K_obs, precisions - latents)\n",
    "    MSE_precision = utils.error_norm(K, precisions)\n",
    "    MSE_latent = utils.error_norm(ells, latents)\n",
    "    mean_rank_error = utils.error_rank(ells, latents)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               F1score=F1score,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               note=None,\n",
    "               estimator=mdl)\n",
    "    return res\n",
    "\n",
    "def tgl_results(data_grid, K, K_obs, ells, **params):\n",
    "\n",
    "    mdl = time_graph_lasso_.TimeGraphLasso(\n",
    "        time_on_axis='last', assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=500, rho=1./ np.sqrt(data_grid.shape[0]))\n",
    "\n",
    "    tic = time.time()\n",
    "    ll = mdl.set_params(**params).fit(data_grid)\n",
    "    tac = time.time()\n",
    "    iterations = ll.n_iter_\n",
    "    F1score = utils.structure_error(K, ll.precision_)['f1']\n",
    "    MSE_observed = None # utils.error_norm(K_obs, ll.precision_ - ll.latent_)\n",
    "    MSE_precision = utils.error_norm(K, ll.precision_)\n",
    "    MSE_latent = None # utils.error_norm(ells, ll.latent_)\n",
    "    mean_rank_error = None # utils.error_rank(ells, ll.latent_)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               F1score=F1score,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               likelihood=mdl.score(data_grid),\n",
    "               note=None,\n",
    "               estimator=ll)\n",
    "    return res\n",
    "\n",
    "def ltgl_results(data_grid, K, K_obs, ells, **params):\n",
    "    mdl = latent_time_graph_lasso_.LatentTimeGraphLasso(\n",
    "        time_on_axis='last', assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=1000, rho=1./ np.sqrt(data_grid.shape[0]),\n",
    "        update_rho_options=dict(mu=5))\n",
    "\n",
    "    tic = time.time()\n",
    "    ll = mdl.set_params(**params).fit(data_grid)\n",
    "    tac = time.time()\n",
    "    iterations = ll.n_iter_\n",
    "    ss = utils.structure_error(K, ll.precision_)#, thresholding=1, eps=1e-5)\n",
    "    MSE_observed = utils.error_norm(K_obs, ll.precision_ - ll.latent_)\n",
    "    MSE_precision = utils.error_norm(K, ll.precision_, upper_triangular=True)\n",
    "    MSE_latent = utils.error_norm(ells, ll.latent_)\n",
    "    mean_rank_error = utils.error_rank(ells, ll.latent_)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               note=None,\n",
    "               estimator=ll,\n",
    "               likelihood=mdl.score(data_grid),\n",
    "              latent=ll.latent_)\n",
    "\n",
    "    res = dict(res, **ss)\n",
    "    return res\n",
    "\n",
    "\n",
    "def glasso_results(data_grid, K, K_obs, ells, alpha):\n",
    "    gl = GraphLasso(alpha=alpha, mode='cd', assume_centered=False, max_iter=500)\n",
    "\n",
    "    tic = time.time()\n",
    "    iters = []\n",
    "    precisions = []\n",
    "    for d in data_grid.transpose(2, 0, 1):\n",
    "        gl.fit(d)\n",
    "        iters.append(gl.n_iter_)\n",
    "        precisions.append(gl.precision_)\n",
    "    tac = time.time()\n",
    "    iterations = np.max(iters)\n",
    "    precisions = np.array(precisions)\n",
    "\n",
    "    ss = utils.structure_error(K, precisions)#, thresholding=1, eps=1e-5)\n",
    "\n",
    "    MSE_observed = None\n",
    "    MSE_precision = utils.error_norm(K, precisions, upper_triangular=True)\n",
    "    MSE_latent = None\n",
    "    mean_rank_error = None\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               likelihood=likelihood_score(data_grid.transpose(2, 0, 1), precisions),\n",
    "               note=None,\n",
    "               estimator=gl)\n",
    "\n",
    "    res = dict(res, **ss)\n",
    "    return res\n",
    "\n",
    "\n",
    "def friedman_results(data_grid, K, K_obs, ells, alpha):\n",
    "    tic = time.time()\n",
    "    iters = []\n",
    "    precisions = []\n",
    "    for d in data_grid.transpose(2,0,1):\n",
    "        emp_cov = empirical_covariance(d)\n",
    "        out = glasso(emp_cov, alpha)\n",
    "        iters.append(int(out[-1][0]))\n",
    "        precisions.append(np.array(out[1]))\n",
    "    tac = time.time()\n",
    "    iterations = np.max(iters)\n",
    "    precisions = np.array(precisions)\n",
    "    F1score = utils.structure_error(K, precisions)['f1']\n",
    "    MSE_observed = None\n",
    "    MSE_precision = utils.error_norm(K, precisions, upper_triangular=True)\n",
    "    MSE_latent = None\n",
    "    mean_rank_error = None\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               F1score=F1score,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               likelihood=likelihood_score(data_grid.transpose(2, 0, 1), precisions),\n",
    "               note=None,\n",
    "               estimator=None)\n",
    "\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def hallac_results(data_grid, K, K_obs, ells, beta, alpha, penalty=2):\n",
    "\n",
    "#     with suppress_stdout():\n",
    "    tic = time.time()\n",
    "    thetaSet, empCovSet, status, gvx = TVGL.TVGL(\n",
    "        np.vstack(data_grid.transpose(2,0,1)), data_grid.shape[0], lamb=alpha, beta=beta,\n",
    "        indexOfPenalty=penalty)\n",
    "    tac = time.time()\n",
    "\n",
    "    if status != \"Optimal\":\n",
    "        print (\"not converged\")\n",
    "    precisions = np.array(thetaSet)\n",
    "    ss = utils.structure_error(K, precisions)\n",
    "    MSE_observed = None\n",
    "    MSE_precision = utils.error_norm(K, precisions, upper_triangular=True)\n",
    "    MSE_latent = None\n",
    "    mean_rank_error = None\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=gvx.n_iter_,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               likelihood=likelihood_score(data_grid.transpose(2, 0, 1), precisions),\n",
    "               note=status,\n",
    "               estimator=gvx)\n",
    "    res = dict(res, **ss)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "try:\n",
    "    eng.quit()\n",
    "except:\n",
    "    pass\n",
    "eng = matlab.engine.start_matlab()\n",
    "eng.addpath(r'/home/fede/src/slipguru/regain/regain/wrapper/lvglasso/',nargout=0)\n",
    "# eng.addpath(r'path/to/ADMM_B.m/',nargout=0)\n",
    "\n",
    "def chandresekeran_results(data_grid, K, K_obs, ells, tau, alpha, **whatever):\n",
    "\n",
    "    emp_list = np.array([empirical_covariance(x, assume_centered=True)\n",
    "                        for x in data_grid.transpose(2,0,1)]).transpose(1,2,0)\n",
    "\n",
    "    n_samples = emp_list.shape[0]\n",
    "    rho = 1./ np.sqrt(data_grid.shape[0])\n",
    "\n",
    "    # 3. Matlab engine\n",
    "    result = eng.LVGLASSO(matlab.double(emp_list.tolist()),float(alpha),float(tau),float(rho))\n",
    "    ma_output = Bunch(**result)\n",
    "\n",
    "    R = np.array(ma_output.R)\n",
    "    S = np.array(ma_output.S)\n",
    "    L = np.array(ma_output.L)\n",
    "\n",
    "    ss = utils.structure_error(K, S)\n",
    "    MSE_observed = utils.error_norm(K_obs, R)\n",
    "    MSE_precision = utils.error_norm(K, S, upper_triangular=True)\n",
    "    MSE_latent = utils.error_norm(ells, L)\n",
    "    mean_rank_error = utils.error_rank(ells, L)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=ma_output.elapsed_time,\n",
    "               iterations=np.max(ma_output.iter),\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               note=None, estimator=ma_output,\n",
    "               likelihood=likelihood_score(data_grid.transpose(2, 0, 1), R),\n",
    "              latent=L)\n",
    "\n",
    "    res = dict(res, **ss)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting 1\n",
    "alpha = 0.45 #0.0025\n",
    "tau = 3\n",
    "beta = 50 # 1000\n",
    "eta = 10\n",
    "\n",
    "n_samples = 100\n",
    "n_dim_lat = 20\n",
    "T = 10\n",
    "n_dim_obs = 100\n",
    "\n",
    "k = (n_dim_obs, T)\n",
    "\n",
    "np.random.seed(20)\n",
    "\n",
    "# mode = 'norm'\n",
    "reload(datasets)\n",
    "data = {(dim, T) : datasets.make_dataset(\n",
    "#     mode=mode,\n",
    "    update_theta='l2', update_ell='l2', normalize_starting_matrices=True,\n",
    "    n_samples=n_samples, n_dim_lat=n_dim_lat, n_dim_obs=dim,  T=T, epsilon=1e-1,\n",
    "    proportional=True, degree=2, keep_sparsity=True)\n",
    "    for dim in [n_dim_obs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 2\n",
    "alpha = .43\n",
    "tau = 1.9\n",
    "beta = 1\n",
    "eta = 2\n",
    "\n",
    "n_samples = 100 # 500\n",
    "n_dim_lat = 5\n",
    "T = 100\n",
    "n_dim_obs = 50\n",
    "\n",
    "k = (n_dim_obs, T)\n",
    "\n",
    "np.random.seed(20)\n",
    "reload(datasets)\n",
    "# data = {(dim, T) : datasets.generate_dataset(\n",
    "#     mode='fixed', n_samples=n_samples, n_dim_lat=n_dim_lat, n_dim_obs=dim,  T=T, epsilon=1e-3, degree=3)\n",
    "#     for dim in n_dims}\n",
    "data = {(dim, T) : datasets.make_dataset(\n",
    "    mode='l1l1', n_samples=n_samples, n_dim_lat=n_dim_lat, n_dim_obs=dim,  T=T, epsilon=1e-1,\n",
    "    proportional=False, degree=2, keep_sparsity=True)\n",
    "    for dim in [n_dim_obs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K = data[k].thetas\n",
    "\n",
    "print ([(i!=0).sum() for i in K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[k].thetas == 0).sum() / (n_dim_obs ** 2 * T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print([np.linalg.norm(data[k].thetas[i] - data[k].thetas[i+1]) for i in range(T-1)])\n",
    "print([np.linalg.norm(data[k].ells[i] - data[k].ells[i+1]) for i in range(T-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare dataframe for results\n",
    "n_dims = [n_dim_obs]\n",
    "n_times = [T]\n",
    "methods = ['LTGL ($\\ell_2^2$)', 'LTGL ($\\ell_1$)', 'GL', 'LVGLASSO', 'TVGL ($\\ell_2^2$)', 'TVGL ($\\ell_1$)']\n",
    "scores = sorted([\"MSE_precision\", \"MSE_observed\", \"MSE_latent\", 'estimator',\n",
    "                 \"mean_rank_error\", 'time','iterations', 'precision', 'recall', 'accuracy', 'balanced_accuracy',\n",
    "                'f1', 'npv', 'prevalence', 'miss_rate', 'likelihood',\n",
    "                'specificity', 'plr',  'nlr'])\n",
    "\n",
    "cols = pd.MultiIndex.from_product([scores, n_dims], names=('score','dim'))\n",
    "rows = pd.MultiIndex.from_product([methods, n_times], names=('method','time'))\n",
    "\n",
    "dff = pd.DataFrame(columns=cols, index=rows)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setting 1\n",
    "alpha = 0.361 #289 #0.0025\n",
    "tau = 1.12\n",
    "beta = 5e2\n",
    "eta = 5\n",
    "alpha_chandri_setting_1 = 0.29\n",
    "\n",
    "# # setting 2\n",
    "# alpha = .43 #0.0025\n",
    "# tau = 1.99\n",
    "# beta = 2\n",
    "# eta = 20\n",
    "# alpha_gl_setting_2 = .35\n",
    "\n",
    "for i, (k, res) in enumerate(sorted(data.items())[:5]):\n",
    "    dim = k[0]\n",
    "    print(\"Start with: dim=%d, T=%d (it %d)\" % (k[0],k[1], i))\n",
    "    data_list = res.data\n",
    "    K = res.thetas\n",
    "    K_obs = res.thetas_observed\n",
    "    ells = res.ells\n",
    "    data_grid = np.array(data_list).transpose(1,2,0)  # to use it later for grid search\n",
    "\n",
    "    print(\"starting LTGL l1...\\r\", end='')\n",
    "    res_l = ltgl_results(data_grid, K, K_obs, ells, \n",
    "                       alpha=alpha, beta=beta, verbose=0, max_iter=1000,\n",
    "                       tau=tau, eta=eta, psi='l1', phi='laplacian', tol=1e-5, rtol=1e-5)\n",
    "    dff.loc[idx['LTGL ($\\ell_1$)', k[1]], idx[:, k[0]]] = [res_l[x] for x in scores]\n",
    "    \n",
    "    print(\"starting LTGL l2...\\r\", end='')\n",
    "    res_l = ltgl_results(data_grid, K, K_obs, ells, \n",
    "                       alpha=alpha, beta=beta,\n",
    "                       tau=tau, eta=eta, psi='laplacian', phi='laplacian', tol=1e-5, rtol=1e-5)\n",
    "    dff.loc[idx['LTGL ($\\ell_2^2$)', k[1]], idx[:, k[0]]] = [res_l[x] for x in scores]\n",
    "    \n",
    "    print(\"starting GL ...\\r\", end='')\n",
    "    try:\n",
    "        res = glasso_results(data_grid, K, K_obs, ells, alpha=alpha)\n",
    "#         res = glasso_results(data_grid, K, K_obs, ells, alpha=alpha_gl_setting_2)\n",
    "\n",
    "        # res = friedman_results(data_grid, K, K_obs, ells, alpha=alpha)\n",
    "        dff.loc[idx['GL', k[1]], idx[:, k[0]]] = [res[x] for x in scores]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(\"starting LVGLASSO...\\r\", end='')\n",
    "#     res_c = chandresekeran_results(data_grid, K, K_obs, ells, tau=tau, alpha=alpha)\n",
    "    res_c = chandresekeran_results(data_grid, K, K_obs, ells, tau=tau, alpha=alpha_chandri_setting_1)\n",
    "    dff.loc[idx['LVGLASSO', k[1]], idx[:, k[0]]] = [res_c[x] for x in scores]\n",
    "    \n",
    "    print(\"starting TVGL L1...\\r\", end='')\n",
    "    res = hallac_results(data_grid, K, K_obs, ells, beta=beta, alpha=alpha, penalty=1)\n",
    "    dff.loc[idx['TVGL ($\\ell_1$)', k[1]], idx[:, k[0]]] = [res[x] for x in scores]\n",
    "    \n",
    "    print(\"starting TVGL L22...\\r\", end='')\n",
    "    res = hallac_results(data_grid, K, K_obs, ells, beta=beta, alpha=alpha, penalty=3)\n",
    "    dff.loc[idx['TVGL ($\\ell_2^2$)', k[1]], idx[:, k[0]]] = [res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mm = dff.xs(n_dim_obs, level='dim', axis=1).xs(T, level='time')\n",
    "# mm['likelihood']\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = dff.xs(n_dim_obs, level='dim', axis=1).xs(T, level='time')\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "' & '.join(['%.3f' % Decimal(i) for i in mm['MSE_precision']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dff[[s for s in scores if s != 'estimator']].to_pickle(\"dff_setting_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LTGL ($\\ell_2^2$)'].latent_])\n",
    "l2 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LTGL ($\\ell_1$)'].latent_])\n",
    "l3 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LVGLASSO'].L])\n",
    "\n",
    "l4 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LTGL ($\\ell_2^2$)'].latent_])\n",
    "l5 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LTGL ($\\ell_1$)'].latent_])\n",
    "l6 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LVGLASSO'].L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1,l2,l3,l4,l5,l6 = utils.load_pickle(filename=\"ells.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2,1, sharey=False, figsize=(10,5), dpi=600)\n",
    "\n",
    "colors = ['white', 'lightblue', 'C7']\n",
    "alpha = 0.95\n",
    "\n",
    "counter=collections.Counter(l1)\n",
    "ax1.bar(counter.keys(), np.array(counter.values())/len(l1), \n",
    "        alpha=alpha, width=0.24, label='LTGL ($\\ell_2^2$)', color=colors[0], edgecolor='k')\n",
    "counter=collections.Counter(l2)\n",
    "ax1.bar(np.array(counter.keys())+0.25, np.array(counter.values())/len(l1), \n",
    "        alpha=alpha, width=0.24, label='LTGL ($\\ell_1$)', color=colors[1], edgecolor='k')\n",
    "counter=collections.Counter(l3)\n",
    "ax1.bar(np.array(counter.keys())-0.25, np.array(counter.values())/len(l1), \n",
    "        alpha=alpha, width=0.24, label='LVGLASSO', color=colors[2], edgecolor='k')\n",
    "\n",
    "ax1.set_xticks(range(0,30, 2))\n",
    "#ax1.set_ylim(0,5)\n",
    "ax1.axvline(20, c='r', ls='--')\n",
    "ax1.set_xlabel(r'ranks of L obtained with ($p_2$)')\n",
    "ax1.set_ylabel('frequency')\n",
    "# ax1.set_xscale(\"log\")\n",
    "# ax1.set_xlim([10, 100])\n",
    "ax1.xaxis.label.set_size(15)\n",
    "ax1.yaxis.label.set_size(15)\n",
    "\n",
    "#ax1.legend()\n",
    "# ax0.legend(prop={'size': 10})\n",
    "# ax0.set_title('bars with legend')\n",
    "\n",
    "\n",
    "counter=collections.Counter(l4)\n",
    "ax2.bar(counter.keys(), np.array(counter.values())/len(l4), \n",
    "        alpha=alpha, width=0.24, label='LTGL ($\\ell_2^2$)', color=colors[0], edgecolor='k')\n",
    "counter=collections.Counter(l5)\n",
    "ax2.bar(np.array(counter.keys())+0.25,  \n",
    "        np.array(counter.values())/len(l4), alpha=alpha, width=0.24, label='LTGL ($\\ell_1$)', color=colors[1],\n",
    "        edgecolor='k')\n",
    "counter=collections.Counter(l6)\n",
    "ax2.bar(np.array(counter.keys())-0.25,  \n",
    "        np.array(counter.values())/len(l4), alpha=alpha, width=0.24, label='LVGLASSO', color=colors[2],\n",
    "       edgecolor='k')\n",
    "\n",
    "ax2.set_xticks(range(0,30,2))\n",
    "# ax2.set_xlim(2.5,6.7)\n",
    "ax2.set_xlabel(r'ranks of L obtained with ($p_1$)')\n",
    "ax2.set_ylabel('frequency')\n",
    "ax2.xaxis.label.set_size(15)\n",
    "ax2.yaxis.label.set_size(15)\n",
    "ax2.axvline(5, c='r', ls='--')\n",
    "ax1.legend(loc='upper left', fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "f.savefig(\"ranks_distribution_vertical.pdf\", dpi=600, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10,2.6), dpi=600)\n",
    "\n",
    "colors = ['white', 'lightblue', 'C7']\n",
    "alpha = 0.5\n",
    "\n",
    "counter=collections.Counter(l1)\n",
    "ax1.plot(range(len(l1)), l1, \n",
    "        alpha=alpha, label='LTGL ($\\ell_2^2$)', color=colors[0])\n",
    "counter=collections.Counter(l2)\n",
    "ax1.plot(np.arange(len(l1))+.2, l2, \n",
    "        alpha=alpha,  label='LTGL ($\\ell_1$)', color=colors[1])\n",
    "counter=collections.Counter(l3)\n",
    "ax1.plot(np.arange(len(l1))+.4, l3,\n",
    "        alpha=alpha, label='LVGLASSO', color=colors[2])\n",
    "\n",
    "# ax1.set_xticks(range(15,25, 1))\n",
    "#ax1.set_ylim(0,5)\n",
    "ax1.axhline(20, c='r', ls='--')\n",
    "ax1.set_xlabel(r'ranks of L obtained with ($p_2$)')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax1.xaxis.label.set_size(15)\n",
    "ax1.yaxis.label.set_size(15)\n",
    "\n",
    "#ax1.legend()\n",
    "# ax0.legend(prop={'size': 10})\n",
    "# ax0.set_title('bars with legend')\n",
    "\n",
    "\n",
    "counter=collections.Counter(l4)\n",
    "ax2.plot(range(len(l4)), l4, \n",
    "        alpha=alpha,label='LTGL ($\\ell_2^2$)', color=colors[0])\n",
    "counter=collections.Counter(l5)\n",
    "ax2.plot(np.arange(len(l4))+.2, l5,\n",
    "        alpha=alpha,  label='LTGL ($\\ell_1$)', color=colors[1])\n",
    "counter=collections.Counter(l6)\n",
    "ax2.plot(np.arange(len(l4))+.4, l6, alpha=alpha,label='LVGLASSO', color=colors[2])\n",
    "\n",
    "# ax2.set_xticks(range(10))\n",
    "# ax2.set_xlim(2.5,6.7)\n",
    "ax2.set_xlabel(r'ranks of L obtained with ($p_1$)')\n",
    "ax2.xaxis.label.set_size(15)\n",
    "ax2.axhline(5, c='r', ls='--')\n",
    "ax1.legend(loc='best', fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
