{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Dev notebook]\n",
    "## How does STGL work with TICC data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils.extmath import squared_norm\n",
    "from sklearn.covariance import empirical_covariance\n",
    "from sklearn.cluster.hierarchical import AgglomerativeClustering\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import v_measure_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from regain.utils import structure_error, error_norm_time, normalize_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "from regain.covariance import kernel_time_graphical_lasso_, kernel_latent_time_graphical_lasso_\n",
    "from regain.datasets import kernels; reload(kernels)\n",
    "\n",
    "n_dim = 10\n",
    "w_size = 1\n",
    "n_samples = 50\n",
    "clusters=(0,0,0,0,1,1,1,1,0,0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = kernels.make_ticc_dataset_v3(\n",
    "    clusters=clusters,\n",
    "    w_size=w_size, n_dim=n_dim, n_samples=n_samples)\n",
    "X, y = data.X, data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print the inv matrix\n",
    "# res = sns.clustermap(data.inv, row_cluster=False, col_cluster=False)\n",
    "# ax = res.ax_heatmap\n",
    "# for i in range(n_samples * len(clusters)):\n",
    "#     ax.axvline((i + 1) * n_dim)\n",
    "#     ax.axhline((i + 1) * n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = []\n",
    "for c in np.unique(y):\n",
    "    idx = y == c\n",
    "    cov.append(empirical_covariance(X[idx]))\n",
    "cov = np.asarray(cov)\n",
    "\n",
    "kernel = np.zeros((cov.shape[0], cov.shape[0]))\n",
    "for i in range(cov.shape[0]):\n",
    "    for j in range(i + 1, cov.shape[0]):\n",
    "        kernel[i, j] = kernel[j, i] = (np.linalg.norm((cov[i]) - (cov[j])))\n",
    "\n",
    "mm = np.sum(np.abs(kernel), axis=1)\n",
    "kernel += np.eye(cov.shape[0]) * mm\n",
    "\n",
    "normalize_matrix(kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(kernel_time_graphical_lasso_)\n",
    "reload(kernel_latent_time_graphical_lasso_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.norm import l1_od_norm\n",
    "mdl = kernel_time_graphical_lasso_.SimilarityTimeGraphicalLasso(\n",
    "    psi='l1', max_iter=500, alpha=0.1, beta=1, kernel=kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SLTGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_times = np.unique(y).size\n",
    "\n",
    "# let's use latent variable as well\n",
    "eta = 0.25\n",
    "kernel_phi = np.eye(n_times)\n",
    "np.fill_diagonal(kernel_phi[:, 1:], eta)\n",
    "np.fill_diagonal(kernel_phi[1:], eta)\n",
    "\n",
    "mdl = kernel_latent_time_graphical_lasso_.SimilarityLatentTimeGraphicalLasso(\n",
    "    alpha=1, kernel_phi=kernel_phi, tau=0.9, beta=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.gaussian_process import kernels as skkernels\n",
    "# rbf = kernels.RBF\n",
    "\n",
    "# mdl = kernel_time_graphical_lasso_.KernelTimeGraphicalLasso(psi='l1', max_iter=500, alpha=0.1, beta=1, kernel=rbf).fit(X, y)\n",
    "\n",
    "# from regain.norm import l1_od_norm\n",
    "# mdl.similarity_matrix = kernel_time_graphical_lasso_.precision_similarity(mdl.precision_, l1_od_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.base import clone\n",
    "from regain.covariance import time_graphical_lasso_, latent_time_graphical_lasso_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stgl = kernel_time_graphical_lasso_.SimilarityTimeGraphicalLasso(alpha=1, beta=2).fit(X, y)\n",
    "sltgl = kernel_latent_time_graphical_lasso_.SimilarityLatentTimeGraphicalLasso(alpha=1, tau=0.9, beta=2)\n",
    "clust = AgglomerativeClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ticc import TICC_solver; \n",
    "from imp import reload; reload(TICC_solver)\n",
    "ticc = TICC_solver.TICC(number_of_clusters=np.unique(clusters).size, window_size=1)\n",
    "cluster_assignment, cluster_MRFs = ticc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import v_measure_score\n",
    "v_measure_score(data.id_cluster, cluster_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_stgl = Pipeline([('stgl', clone(stgl)), ('clust', clone(clust))])\n",
    "labels_pred = pipe_stgl.set_params(clust__n_clusters=np.unique(clusters).size).fit_predict(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_measure_score(data.id_cluster, np.repeat(labels_pred, n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitions = np.arange(0.1, 1, 0.1)\n",
    "partitions = [10, 50, 100, 200, 500, 1000]\n",
    "n_splits = 10\n",
    "\n",
    "n_dim = 50\n",
    "w_size = 1\n",
    "n_samples = 1000\n",
    "\n",
    "vs, ne, se = {}, {}, {}\n",
    "for i in partitions:\n",
    "    # v_scores, norm_errors, structure_errors = [], [], []\n",
    "    \n",
    "    # for train, _, in StratifiedShuffleSplit(n_splits=n_splits, train_size=float(i)).split(X, y):\n",
    "    for j in range(n_splits):\n",
    "        n_clusts = np.random.randint(10) + 2\n",
    "        clusters = np.random.choice(list(range(n_clusts)), size=15)\n",
    "        data = kernels.make_ticc_dataset_v3(\n",
    "            clusters=clusters,\n",
    "            w_size=w_size, n_dim=n_dim, n_samples=i)\n",
    "        X, y = data.X, data.y\n",
    "        \n",
    "        n_times = np.unique(y).size\n",
    "        thetas_true = data.precs\n",
    "        thetas_true_sparse = data.sparse_precs\n",
    "        labels_true = data.id_cluster #[::(len(clusters) * i // n_times)]\n",
    "        \n",
    "        thetas_true_sparse_rep = np.array([thetas_true_sparse[l] for l in y])\n",
    "        thetas_true_rep = np.array([thetas_true[l] for l in y])\n",
    "        \n",
    "        # STGL\n",
    "        pipe_stgl = Pipeline([('stgl', clone(stgl)), ('clust', clone(clust))])\n",
    "        tic = time()\n",
    "        labels_pred = pipe_stgl.set_params(clust__n_clusters=np.unique(clusters).size).fit_predict(X, y)\n",
    "        tac = time() - tic\n",
    "        labels_pred = np.repeat(labels_pred, i)\n",
    "        \n",
    "        mdl = pipe_stgl['stgl']\n",
    "        obs_precs = np.array([mdl.get_observed_precision()[l] for l in y])\n",
    "        obs_precs_sparse = np.array([mdl.get_precision()[l] for l in y])\n",
    "        \n",
    "        vs.setdefault(('stgl', i), {}).setdefault('model', []).append(pipe_stgl)\n",
    "        vs.setdefault(('stgl', i), {}).setdefault('v_measure', []).append(\n",
    "            v_measure_score(labels_true, labels_pred))\n",
    "        vs.setdefault(('stgl', i), {}).setdefault('structure_error', []).append(\n",
    "            structure_error(thetas_true_sparse, obs_precs_sparse, no_diagonal=True))\n",
    "        vs.setdefault(('stgl', i), {}).setdefault('error_norm', []).append(\n",
    "            error_norm_time(thetas_true_rep, obs_precs))\n",
    "        vs.setdefault(('stgl', i), {}).setdefault('time', []).append(tac)\n",
    "        \n",
    "        # SLTGL\n",
    "        pipe_sltgl = Pipeline([('sltgl', clone(sltgl)), ('clust', clone(clust))])\n",
    "        eta = 0.25\n",
    "        kernel_phi = np.eye(n_times)\n",
    "        np.fill_diagonal(kernel_phi[:, 1:], eta)\n",
    "        np.fill_diagonal(kernel_phi[1:], eta)\n",
    "        pipe_sltgl.set_params(sltgl__kernel_phi=kernel_phi, clust__n_clusters=np.unique(clusters).size)\n",
    "        tic = time()\n",
    "        labels_pred = pipe_sltgl.fit_predict(X, y)\n",
    "        tac = time() - tic\n",
    "        labels_pred = np.repeat(labels_pred, i)\n",
    "        \n",
    "        mdl = pipe_sltgl['sltgl']\n",
    "        obs_precs = np.array([mdl.get_observed_precision()[l] for l in y])\n",
    "        obs_precs_sparse = np.array([mdl.get_precision()[l] for l in y])\n",
    "        \n",
    "        vs.setdefault(('sltgl', i), {}).setdefault('model', []).append(pipe_sltgl)\n",
    "        vs.setdefault(('sltgl', i), {}).setdefault('v_measure', []).append(\n",
    "            v_measure_score(labels_true, labels_pred))\n",
    "        vs.setdefault(('sltgl', i), {}).setdefault('structure_error', []).append(\n",
    "            structure_error(thetas_true_sparse, obs_precs_sparse, no_diagonal=True))\n",
    "        vs.setdefault(('sltgl', i), {}).setdefault('error_norm', []).append(\n",
    "            error_norm_time(thetas_true_rep, obs_precs))\n",
    "        vs.setdefault(('sltgl', i), {}).setdefault('time', []).append(tac)\n",
    "        \n",
    "        # TGL + similarity\n",
    "        tgl = time_graphical_lasso_.TimeGraphicalLasso(alpha=1, beta=2)\n",
    "        tic = time()\n",
    "        tgl.fit(X, y)        \n",
    "        tac = time() - tic\n",
    "        psi = kernel_time_graphical_lasso_.check_norm_prox(tgl.psi)[0]\n",
    "        tgl_prec_sims = kernel_time_graphical_lasso_.precision_similarity(tgl.get_observed_precision(), psi)\n",
    "        labels_pred = clust.set_params(n_clusters=np.unique(clusters).size).fit_predict(tgl_prec_sims)\n",
    "        labels_pred = np.repeat(labels_pred, i)\n",
    "        mdl = tgl\n",
    "        obs_precs = np.array([mdl.get_observed_precision()[l] for l in y])\n",
    "        obs_precs_sparse = np.array([mdl.get_precision()[l] for l in y])\n",
    "        \n",
    "        vs.setdefault(('tgl', i), {}).setdefault('model', []).append(mdl)\n",
    "        vs.setdefault(('tgl', i), {}).setdefault('v_measure', []).append(\n",
    "            v_measure_score(labels_true, labels_pred))\n",
    "        vs.setdefault(('tgl', i), {}).setdefault('structure_error', []).append(\n",
    "            structure_error(thetas_true_sparse, obs_precs_sparse, no_diagonal=True))\n",
    "        vs.setdefault(('tgl', i), {}).setdefault('error_norm', []).append(\n",
    "            error_norm_time(thetas_true_rep, obs_precs))\n",
    "        vs.setdefault(('tgl', i), {}).setdefault('time', []).append(tac)\n",
    "        \n",
    "        # LTGL + similarity\n",
    "        ltgl = latent_time_graphical_lasso_.LatentTimeGraphicalLasso(alpha=1, beta=2, tau=0.9, eta=0.25)\n",
    "        tic = time()\n",
    "        ltgl.fit(X, y)\n",
    "        tac = time() - tic\n",
    "        psi = kernel_latent_time_graphical_lasso_.check_norm_prox(ltgl.psi)[0]\n",
    "        ltgl_prec_sims = kernel_time_graphical_lasso_.precision_similarity(ltgl.get_observed_precision(), psi)\n",
    "        labels_pred = clust.set_params(n_clusters=np.unique(clusters).size).fit_predict(ltgl_prec_sims)\n",
    "        labels_pred = np.repeat(labels_pred, i)\n",
    "        mdl = ltgl\n",
    "        \n",
    "        obs_precs = np.array([mdl.get_observed_precision()[l] for l in y])\n",
    "        obs_precs_sparse = np.array([mdl.get_precision()[l] for l in y])\n",
    "        \n",
    "        vs.setdefault(('ltgl', i), {}).setdefault('model', []).append(mdl)\n",
    "        vs.setdefault(('ltgl', i), {}).setdefault('v_measure', []).append(\n",
    "            v_measure_score(labels_true, labels_pred))\n",
    "        vs.setdefault(('ltgl', i), {}).setdefault('structure_error', []).append(\n",
    "            structure_error(thetas_true_sparse, obs_precs_sparse, no_diagonal=True))\n",
    "        vs.setdefault(('ltgl', i), {}).setdefault('error_norm', []).append(\n",
    "            error_norm_time(thetas_true_rep, obs_precs))\n",
    "        vs.setdefault(('ltgl', i), {}).setdefault('time', []).append(tac)\n",
    "        \n",
    "        ticc = TICC_solver.TICC(number_of_clusters=np.unique(clusters).size, window_size=1)\n",
    "        tic = time()\n",
    "        cluster_assignment, cluster_MRFs = ticc.fit(X)\n",
    "        tac = time() - tic\n",
    "        \n",
    "        obs_precs = np.array([cluster_MRFs[l] for l in cluster_assignment])\n",
    "        obs_precs_sparse = obs_precs\n",
    "        \n",
    "        vs.setdefault(('ticc', i), {}).setdefault('model', []).append(ticc)\n",
    "        vs.setdefault(('ticc', i), {}).setdefault('v_measure', []).append(\n",
    "            v_measure_score(labels_true, cluster_assignment))\n",
    "        vs.setdefault(('ticc', i), {}).setdefault('structure_error', []).append(\n",
    "            structure_error(thetas_true_sparse_rep, obs_precs_sparse, no_diagonal=True))\n",
    "        vs.setdefault(('ticc', i), {}).setdefault('error_norm', []).append(\n",
    "            error_norm_time(thetas_true_rep, obs_precs)\n",
    "        vs.setdefault(('ticc', i), {}).setdefault('time', []).append(tac)\n",
    "    \n",
    "#     vs.append(v_scores)\n",
    "#     ne.append(norm_errors)\n",
    "#     se.append(structure_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(thetas_true_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([thetas_true_sparse[l] for l in labels_pred]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for i, index in enumerate(partitions):\n",
    "    index = int(index)\n",
    "    for col in range(n_splits):\n",
    "        d.append((dict(sample=index, col=col, val=np.array(vs)[i,col], type='v_scores')))\n",
    "        d.append(dict(sample=index, col=col, val=np.array(ne)[i,col], type='norm_errors'))\n",
    "        d.append(dict(sample=index, col=col, val=np.array(se)[i,col]['balanced_accuracy'], type='structure_errors'))\n",
    "\n",
    "A = pd.DataFrame(d)\n",
    "\n",
    "ax = sns.pointplot(x='sample', y='val', data=A, hue='type')\n",
    "\n",
    "plt.pyplot.gcf().savefig(\"error.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thetas_true = np.array([np.array(data.precs)[x].mean(axis=0) for x in \n",
    "#                         [np.arange(i*(len(clusters) * (n_samples) // n_times),\n",
    "#                                    (i+1)*(len(clusters) * (n_samples) // n_times))  for i in range(len(clusters) * (n_samples) // n_times - 1)]])\n",
    "# thetas_true_sparse= np.array([np.array(data.sparse_precs)[x].mean(axis=0) for x in [np.arange(i*(len(clusters) * (n_samples) // n_times),(i+1)*(len(clusters) * (n_samples) // n_times)) \n",
    "#  for i in range(len(clusters) * (n_samples) // n_times - 1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_true)\n",
    "print(labels_pred)\n",
    "\n",
    "print(v_measure_score(labels_true, labels_pred))\n",
    "print(structure_error(thetas_true_sparse, mdl.get_precision(), no_diagonal=True))\n",
    "print(error_norm_time(thetas_true, mdl.get_observed_precision()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "makeTICC v3 + STGL, SLTGL, TICC, TGL + similarity, LTGL + similarity\n",
    "\n",
    "cluster representative + STGL, SLTGL, TICC, TGL + similarity, LTGL + similarity\n",
    "\n",
    "plot con MCC, vscore, norm error, + 6 plot roc curves coi 10 split e plot_precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
