{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.covariance import empirical_covariance\n",
    "\n",
    "from regain import datasets\n",
    "from regain.covariance import latent_graphical_lasso_, latent_time_graphical_lasso_\n",
    "\n",
    "# config\n",
    "np.random.seed(0)\n",
    "n_samples = 100\n",
    "n_dim_obs = 10\n",
    "n_dim_lat = 2\n",
    "T = 10\n",
    "tau = 0.1\n",
    "alpha = 0.1\n",
    "\n",
    "dataset = datasets.make_dataset(\n",
    "        n_samples=n_samples, n_dim_lat=n_dim_lat, update_ell='fixed',\n",
    "        update_theta='l2', normalize_starting_matrices=True, n_dim_obs=n_dim_obs, T=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Single timestamp\n",
    "Check if, with only one timestamp, the method behave the same as Chandrasekaran/Ma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_cov = empirical_covariance(dataset.data[0], assume_centered=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Do we behave as ourselves with the same functional as Ma?\n",
    "The following is the latent time graphical model inference with only one covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_time = latent_time_graphical_lasso_.latent_time_graphical_lasso(\n",
    "    emp_cov[None, ...], alpha=alpha, tau=tau,\n",
    "    tol=1e-5, rtol=1e-5, rho=1./ emp_cov.shape[0],\n",
    "    verbose=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare it with the code for the latent graphical model inference (without time). <br>\n",
    "Since there is only one covariance matrix, we expect to obtain the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_static = latent_graphical_lasso_.latent_graphical_lasso(\n",
    "    emp_cov, alpha=alpha, tau=tau, \n",
    "    tol=1e-5, rtol=1e-5, rho=1. / emp_cov.shape[0],\n",
    "    verbose=0, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all([np.allclose(x, y) for x, y in zip(results_static, results_time)])\n",
    "assert np.linalg.matrix_rank(results_static[1]) == np.linalg.matrix_rank(results_time[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional (requires Matlab installed)\n",
    "Now we check if the result is the same as the LVGLASSO Matlab algorithm. To do that, we implemented a simple wrapper which rely on `matlab.engine`, to run Matlab code directly from Python. It requires Matlab 2016 or higher installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.wrapper import lvglasso\n",
    "from sklearn.datasets.base import Bunch\n",
    "\n",
    "result = lvglasso(emp_cov, alpha, tau)\n",
    "ma_output = Bunch(**result)\n",
    "\n",
    "assert np.all([np.allclose(x, y, atol=1e-4) for x, y in zip(results_static[:2], (ma_output.S, ma_output.L))])\n",
    "assert np.linalg.matrix_rank(ma_output.L) == np.linalg.matrix_rank(results_time[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time-varying vs separate for each time\n",
    "This is to justify the choice of the additional penalties which constrain subsequent matrices in time to behave similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "n_samples = 100\n",
    "n_dim_obs = 10\n",
    "n_dim_lat = 2\n",
    "T = 10\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "dataset = datasets.make_dataset(\n",
    "        n_samples=n_samples, n_dim_lat=n_dim_lat, update_ell='fixed',\n",
    "        update_theta='l2', normalize_starting_matrices=True, n_dim_obs=n_dim_obs, T=T)\n",
    "\n",
    "X, y = dataset.X, dataset.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check again if the results are the same with beta and eta is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_cov = np.array([empirical_covariance(data, assume_centered=False) for data in dataset.data])\n",
    "emp_list = np.array(emp_cov).transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_time = latent_time_graphical_lasso_.latent_time_graphical_lasso(\n",
    "    emp_cov, alpha=alpha, tau=tau, tol=1e-5, rtol=1e-5, rho=1./ emp_cov.shape[0],\n",
    "    beta=0, eta=0,\n",
    "    verbose=0, max_iter=500)\n",
    "\n",
    "results_static = [latent_graphical_lasso_.latent_graphical_lasso(\n",
    "    x, alpha=alpha, tau=tau, tol=1e-5, rtol=1e-5, rho=1. / emp_cov.shape[0],\n",
    "    verbose=0, max_iter=500) for x in emp_cov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all([np.allclose(results_static[i][0], results_time[0][i], atol=1e-2) for i in range(10)])\n",
    "assert np.all([np.linalg.matrix_rank(results_static[i][1]) == np.linalg.matrix_rank(results_time[1][i])\n",
    "        for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, optional: it requires Matlab installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lvglasso(emp_list, alpha, tau)\n",
    "ma_output = Bunch(**result)\n",
    "\n",
    "ma_output.R = np.array(ma_output.R)\n",
    "ma_output.S = np.array(ma_output.S)\n",
    "ma_output.L = np.array(ma_output.L)\n",
    "\n",
    "assert np.allclose(results_time[0], ma_output.R + ma_output.L, atol=1e-3)\n",
    "\n",
    "L = np.array(ma_output.L)\n",
    "LL = results_time[1]\n",
    "\n",
    "ranks_ma = [np.linalg.matrix_rank(l)for l in L]\n",
    "ranks_ours = [np.linalg.matrix_rank(l)for l in LL]\n",
    "assert np.all([np.linalg.matrix_rank(l) == np.linalg.matrix_rank(ll) for l, ll in zip(L, LL)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty contribution\n",
    "\n",
    "We now checked that in the limit case of one time and in the case in which we do not consider the penalties that involve time we perform equivalentely. Now, with CV on the parameters on synhtetic data generated with norm2 we want to see if our method performs better than LVGLASSO applied on different time stamps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from regain import utils\n",
    "from regain.covariance import LatentTimeGraphicalLasso\n",
    "\n",
    "ltgl = GridSearchCV(\n",
    "    LatentTimeGraphicalLasso(),\n",
    "    dict(tau=np.logspace(-2,np.log(.5),10), alpha=np.logspace(-2,np.log(.5),10)),\n",
    "    cv=StratifiedShuffleSplit(10), return_train_score=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_list = list(ltgl.best_estimator_.covariance_)\n",
    "alpha = ltgl.best_params_['alpha']\n",
    "tau = ltgl.best_params_['tau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precs = []\n",
    "lats = []\n",
    "covss = []\n",
    "for data in dataset.data:\n",
    "    lgl = LatentGraphicalLasso(tau=tau, alpha=alpha, assume_centered=False).fit(X, y)\n",
    "    precs.append(lgl.precision_)\n",
    "    lats.append(lgl.latent_)\n",
    "    covss.append(lgl.covariance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error obtained w.r.t. the observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.utils import error_norm_time\n",
    "print(\"Error norm time with observed precision: \\n LTGL: {:.3f}\\n LVGLASSO: {:.3f}\".format(\n",
    "      error_norm_time(ltgl.best_estimator_.precision_ - ltgl.best_estimator_.latent_, dataset.thetas_observed),\n",
    "      error_norm_time(np.array(precs) - np.array(lats), dataset.thetas_observed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error obtained w.r.t. the real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error norm time of LTGL: \\n Precision: {:.3f}\\n Latent: {:.3f}\\n\".format(\n",
    "      error_norm_time(ltgl.best_estimator_.precision_, dataset.thetas),\n",
    "      error_norm_time(ltgl.best_estimator_.latent_, dataset.ells)))\n",
    "\n",
    "print(\"Error norm time of LVGLASSO: \\n Precision: {:.3f}\\n Latent: {:.3f}\".format(\n",
    "      error_norm_time(np.array(precs), dataset.thetas),\n",
    "      error_norm_time(np.array(lats), dataset.ells)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error in ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ltgl.best_estimator_.set_params(beta=1e12,eta=1e12).fit(data_grid)\n",
    "print(\"Rank latent matrices LTGL: {}\".format([np.linalg.matrix_rank(i) for i in ltgl.best_estimator_.latent_]))\n",
    "print(\"Rank latent matrices LVGLASSO: {}\".format([np.linalg.matrix_rank(i) for i in lats]))\n",
    "print(\"Rank true latent matrices: {}\".format(np.linalg.matrix_rank(dataset.ells)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error in structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.utils import structure_error\n",
    "\n",
    "print(\"f1 score LTGL: {:.2f}\".format(structure_error(\n",
    "    dataset.thetas, ltgl.best_estimator_.precision_, thresholding=1, eps=1e-2)['f1']))\n",
    "print(\"f1 score LVGLASSO: {:.2f}\".format(structure_error(\n",
    "    dataset.thetas, np.array(precs), thresholding=1, eps=1e-2)['f1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
